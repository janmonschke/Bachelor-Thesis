### SEO
Search Engine Optimization is very important for modern websites to get a good ranking in search results from Google or any other search engine. Search engines build their indexes with so called Web crawlers [http://en.wikipedia.org/wiki/Web_crawler] that process the contents of websites to get an understanding to what topics they are related. Web crawlers automatically follow links on web pages to create relations between websites and to find out the importance of websites by counting the links that lead to a certain page. They are built to rapidly crawl through many websites which means that the basic crawlers neither load images nor CSS files, nor JavaScript files to improve the load time. This has a negative impact on SPWAs because the content would not be correctly indexed or even not get indexed at all because the client-side JavaScript based url-router would not get started when a Web crawler is on the website since they don't run JavaScript. Furthermore if the start page of your website is also generated by the JavaScript templating system your page wouldn't even get added to any search engine index because the crawler would just see a blank HTML page. Until Web crawlers will properly run JavaScript, SPWAs will not properly get indexed. This makes them for now unusable for client projects that need to have a good ranking in search engines. But there are ways to go around this problem:
Google proposed a technique that let's their crawler index an SPWA [http://code.google.com/intl/de/web/ajaxcrawling/docs/getting-started.html]. When their crawler finds a URL with in typical #!-style it will request a special URL on your server that should return a HTML snapshot of the requested page that represents the content to be indexed. So a request to mydomain.tld/#!/test would create a Web crawler request to mydomain.tld/?_escaped_fragment_=test and the server should respond with the HTML snapshot. This solution can easily lead to a lot of duplicated code since you need to have a router in the backend that needs to work exactly like the one in your front-end to map the URLs that the Web crawler created. Also you might in addition need to duplicate view-code because you often can't use the same view files in the frontend as in the backend.
One thing to keep in mind with this technique is that currently only the Google Web crawler supports the advanced URL scheme and none of the other competitors such as Bing and Yahoo. 
Another method to have a SPWA indexed in search engine rankings works especially for community pages where there is a difference between the site a user sees when he is logged in and the site he sees when he is not logged in. In that case you could serve all public pages, which might not be as many as internal pages (index, about, pricing, help etc...), from the backend so that they easily can get indexed by Web crawlers because you don't want to have the internal pages to get indexed anyway. The extra effort that is needed for this technique is reasonable since only few pages need a backend view and most of the client side code doesn't need to get duplicated.